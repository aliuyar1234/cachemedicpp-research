# Second model smoke test (v1.1, fast-track variant)
# Confirms qualitative robustness/stability on a larger GPT-2 family model.

seed: 777
device: cuda
dtype: bfloat16

model:
  name: gpt2-large
  revision: null
  attn_implementation: eager
  use_cache: true

repair:
  family: A
  rank: 8
  protect_layers: [20, 21, 22, 23]
  share_across_heads: true
  apply_to: KV
  alpha_max: 0.9

corruption:
  mixture: default_mix
  eps_grid: [0.0, 0.02, 0.04, 0.08]
  axes:
    layer_mode: all
    head_mode: bernoulli
    p_head: 0.25
    time_mode: old_only
    N_recent: 64
  params:
    dropout_p: 0.02
    bitflip_p: 0.0005
    bitflip_eps_jump: 8.0
    quant_bits: 8
    rotation_seed: 999
    overwrite_window: [32, 96]
    donor_prompt: "Donor: Deterministic donor prompt for second-model overwrite evaluation."

train:
  steps: 4000
  lr: 0.0002
  batch_size: 1
  prefix_len: 96
  temperature: 2.0
  lambda_id: 1.0
  lambda_contr: 0.5
  alpha_contr: 0.8
  clean_batch_prob: 0.2
  grad_clip: 1.0
  log_every: 50
  save_every: 1000

baseline:
  smoothing_beta: 0.3
  dropout_p: 0.02
  clip_val: 6.0
  target_rms: 1.0

eval:
  max_seq_len: 256
  measure_overhead: true
  ood_protocol: null
  tasks:
    - name: wikitext2_ppl
      num_examples: 500
    - name: needle_long_context
      num_examples: 100
  corruption_eval:
    eps: [0.0, 0.04, 0.08]
    types: [gaussian, orthogonal_rotation, bitflipish_sparse]

stability:
  num_prompts: 100
  delta_norms: [0.0, 0.5, 1.0]
  num_directions: 6
  topk_logits: 1000
  layers: [20, 21, 22, 23]
  time_mode: old_only
  N_recent: 64

data:
  use_offline: false
  offline_paths:
    wikitext2: data/offline/wikitext2_sample.txt
    sst2: data/offline/sst2_sample.jsonl
  long_context:
    seed: 2025
    context_len: 3072
    needle_token: the_key
    needle_value: violet-7
    position_frac: 0.35
    question_template: "Question: What is {needle_token}? Answer:"
