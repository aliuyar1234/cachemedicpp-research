{
  "sweep_name": "recovery_second_model_gpt2_large_v1",
  "base_config": "E:\\Research\\cachemedic_pp_harness_v1_1\\cachemedic_pp_harness\\configs\\fast_paper_base.yaml",
  "num_runs": 1,
  "runs": [
    {
      "name": "second_model_gpt2_large_vonly_tuned",
      "run_dir": "E:\\Research\\cachemedic_pp_harness_v1_1\\cachemedic_pp_harness\\empty_dirs_for_codex\\outputs\\runs_recovery\\recovery_second_model_gpt2_large_v1\\second_model_gpt2_large_vonly_tuned",
      "overrides": {
        "model.name": "gpt2-large",
        "eval.ood_protocol": null,
        "repair.family": "A",
        "repair.apply_to": "V",
        "repair.rank": 4,
        "repair.protect_layers": [
          16,
          17
        ],
        "train.steps": 2000,
        "train.lambda_id": 4.0,
        "train.lambda_contr": 3.0,
        "train.alpha_contr": 0.75,
        "train.clean_batch_prob": 0.45,
        "eval.corruption_eval.eps": [
          0.0,
          0.08,
          0.16
        ],
        "eval.corruption_eval.types": [
          "gaussian",
          "orthogonal_rotation",
          "contiguous_overwrite"
        ],
        "stability.num_prompts": 80,
        "stability.num_directions": 4,
        "eval.tasks": [
          {
            "name": "wikitext2_ppl",
            "num_examples": 400
          },
          {
            "name": "sst2_prompted",
            "num_examples": 250
          },
          {
            "name": "needle_long_context",
            "num_examples": 80
          }
        ]
      },
      "train": {
        "run_id": "second_model_gpt2_large_vonly_tuned",
        "run_dir": "E:\\Research\\cachemedic_pp_harness_v1_1\\cachemedic_pp_harness\\empty_dirs_for_codex\\outputs\\runs_recovery\\recovery_second_model_gpt2_large_v1\\second_model_gpt2_large_vonly_tuned",
        "steps": 2000,
        "last_step": 2000,
        "status": "completed",
        "resumed": false,
        "resumed_from": null
      },
      "eval": {
        "run_id": "second_model_gpt2_large_vonly_tuned",
        "status": "completed",
        "best_heuristic": "smoothing",
        "robustness_auc": {
          "no_defense": 0.04717004680487946,
          "best_heuristic": 0.04720688551888036,
          "cachemedic": 0.04748586656120675
        },
        "elapsed_wall_sec": 1291.5867045999985,
        "resumed": false
      },
      "stability": {
        "run_id": "second_model_gpt2_large_vonly_tuned",
        "status": "completed",
        "points": 3,
        "layers": 4,
        "heads": 20,
        "best_heuristic": "smoothing",
        "checkpoint_loaded": true,
        "elapsed_wall_sec": 898.8877091000031,
        "resumed": false
      },
      "plots": {
        "status": "ok",
        "figures": [
          "figA_score_vs_eps.png",
          "figB_clean_vs_overhead_pareto.png",
          "figC_logit_sensitivity.png",
          "figD_amplification_map.png"
        ],
        "tables": [
          "table_main_results.tex",
          "table_ablation_summary.tex"
        ]
      }
    }
  ],
  "budget": {
    "max_total_gpu_hours": 6,
    "per_run_gpu_hours_hint": 4,
    "notes": "Second-model qualitative confirmation with tuned V-only Option A."
  },
  "status": "completed",
  "paused_run": null
}
