\section{Introduction}

The KV cache enables fast decoding by storing past keys and values, but it also creates a persistent internal state that can be corrupted or manipulated. This paper studies \textbf{KV-cache integrity} and proposes a lightweight stabilization operator.

\paragraph{Contributions.}
\begin{itemize}
  \item We introduce CacheMedic++, a learned KV-cache stability operator $R_\phi$ inserted before attention logits, with frozen base model weights.
  \item We train $R_\phi$ via self-distillation under a reproducible corruption family and add an explicit contraction penalty to encourage state stability.
  \item We treat stability metrics as primary results, reporting logit sensitivity curves and per-layer/head amplification maps, and we validate transfer qualitatively on a second model.
\end{itemize}

\begin{figure}[t]
  \centering
  \FigOrBox[width=0.95\linewidth]{figures/figA_score_vs_eps.png}
  \caption{Robustness curves (task score vs corruption severity).}
  \label{fig:robustness}
\end{figure}
